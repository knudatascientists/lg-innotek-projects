{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 43,  22,  30],\n",
       "        [ 47,  26,  34],\n",
       "        [ 41,  20,  28],\n",
       "        ...,\n",
       "        [201, 181, 186],\n",
       "        [200, 180, 185],\n",
       "        [201, 181, 186]],\n",
       "\n",
       "       [[ 43,  22,  30],\n",
       "        [ 47,  26,  34],\n",
       "        [ 44,  23,  31],\n",
       "        ...,\n",
       "        [204, 184, 189],\n",
       "        [204, 184, 189],\n",
       "        [205, 185, 190]],\n",
       "\n",
       "       [[ 42,  24,  31],\n",
       "        [ 46,  28,  35],\n",
       "        [ 42,  24,  31],\n",
       "        ...,\n",
       "        [202, 182, 187],\n",
       "        [202, 182, 187],\n",
       "        [203, 183, 188]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[229, 192, 194],\n",
       "        [229, 192, 194],\n",
       "        [228, 191, 193],\n",
       "        ...,\n",
       "        [255, 252, 253],\n",
       "        [255, 252, 253],\n",
       "        [255, 252, 253]],\n",
       "\n",
       "       [[229, 192, 194],\n",
       "        [229, 192, 194],\n",
       "        [228, 191, 193],\n",
       "        ...,\n",
       "        [255, 254, 254],\n",
       "        [255, 253, 254],\n",
       "        [255, 254, 254]],\n",
       "\n",
       "       [[229, 192, 194],\n",
       "        [229, 192, 194],\n",
       "        [228, 191, 193],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('./test_img/face_detect01.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흑백이미지 변환\n",
    "gray_img =img[:,:,0] = img[:,:,0] *0.114+img[:,:,1] *0.587+ img[:,:,2] *0.299\n",
    "gray_img= np.uint8(gray_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('gray', gray_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsv 변환\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "img_hsv2 = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "img_hsv[:,:,1]=img_hsv[:,:,1] *0.2\n",
    "img_hsv2[:,:,2]=np.where(img_hsv[:,:,2] *1.3<=255, img_hsv[:,:,2] *1.3, 255)\n",
    "\n",
    "img_hsv = np.uint8(img_hsv)\n",
    "img_hsv = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "img_hsv2 = np.uint8(img_hsv2)\n",
    "img_hsv2 = cv2.cvtColor(img_hsv2, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_hsv', img_hsv)\n",
    "cv2.imshow('img_hsv2', img_hsv2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인물 얼굴 보정\n",
    "def make_up(img):\n",
    "    # hsv 변환\n",
    "    # img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img_hsv2 = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # img_hsv[:,:,1]=img_hsv[:,:,1] *1.5\n",
    "    img_hsv2[:,:,2]=np.where(img_hsv2[:,:,2] *1.7<=255, img_hsv2[:,:,2] *1.7, 255)\n",
    "\n",
    "    # img_hsv = np.uint8(img_hsv)\n",
    "    # img_hsv = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "    img_hsv2 = np.uint8(img_hsv2)\n",
    "    img_hsv2 = cv2.cvtColor(img_hsv2, cv2.COLOR_HSV2BGR)\n",
    "    # cv2.imshow('img', img)\n",
    "    # cv2.imshow('img_hsv', img_hsv)\n",
    "    # cv2.imshow('img_hsv2', img_hsv2)\n",
    "    # cv2.waitKey()\n",
    "    return img_hsv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_img/face_detect06.jpg')\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "face = faces[0]\n",
    "img_face = img[ face[1]:face[1]+face[3],face[0]:face[0]+face[2]]\n",
    "img_hsv2=make_up(img_face)\n",
    "img[ face[1]:face[1]+face[3],face[0]:face[0]+face[2]] = img_hsv2\n",
    "img = cv2.resize(img, (0,0), fx = 0.3, fy = 0.3, interpolation=cv2.INTER_NEAREST)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img_face', img_face)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram equlization 대비 평탄화\n",
    "img = cv2.imread('./test_img/face_detect01.jpg')\n",
    "\n",
    "img_equl= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_equl2 = cv2.equalizeHist(img_equl)\n",
    "cv2.imshow('img_equl', img_equl)\n",
    "cv2.imshow('img_equl2', img_equl2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_equl= cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "img_equl[:,:,0] = cv2.equalizeHist(img_equl[:,:,0])\n",
    "img_equl= cv2.cvtColor(img_equl, cv2.COLOR_YCrCb2BGR)\n",
    "cv2.imshow('img_equl', img_equl)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 221], dtype=uint8), array([ 41481,   2340,   4648,   2287,   2341,   1686,   1222,    965,\n",
      "          962,    887,    838,    801,    749,    987,    768,   1695,\n",
      "          957,  15526,   1548,    719,    780,    543,    551,    466,\n",
      "          452,    415,    339,    308,    299,    288,    283,    270,\n",
      "          229,    234,    225,    205,    203,    191,    185,    189,\n",
      "          164,    152,    160,    145,    123,    130,    127,    106,\n",
      "           98,     85,    102,     77,     87,     64,     61,     93,\n",
      "           51,     59,     64,     63,     60,     75,     59,     56,\n",
      "           65,     63,     61,     63,     54,     52,     69,     62,\n",
      "           63,     58,     44,     74,     48,     59,     54,     62,\n",
      "           51,     52,     56,     51,     60,     50,     71,     78,\n",
      "           67,     65,     61,     74,     70,     67,     85,     72,\n",
      "           75,     84,     72,     93,    110,    104,    112,    125,\n",
      "          110,    110,    116,    112,    109,    137,    156,    155,\n",
      "          158,    165,    168,    181,    191,    240,    219,    288,\n",
      "          369,    385,    516,    502,    693,    631,    843,   1057,\n",
      "          634,   1460,    624,   2712,    691,  35966,    575,   3297,\n",
      "         1450,    462,    852,    330,    489,    277,    336,    272,\n",
      "          181,    204,    171,    180,    194,    216,    230,    238,\n",
      "          241,    286,    300,    383,    491,    563,    755,    747,\n",
      "         1246,   1283,   2590,   2552,   7730,   5634, 819566,   9710,\n",
      "         3086,   2902,   1512,   1373,    808,    916,    474,   1230,\n",
      "          448,    195,    179,    158,    150,    114,    123,    103,\n",
      "          109,    100,     92,     75,     97,     92,     72,     88,\n",
      "           88,     67,     80,     52,     60,     40,     46,     47,\n",
      "           33,     28,     31,     24,     18,     14,     10,     12,\n",
      "           11,      3,      9,      5,      5,      3,      3,      3,\n",
      "            2,      1,      1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 특정 정보 마스킹\n",
    "img = cv2.imread('./test_img/test.jpg')\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(img_hsv,(20,0,0), (40,255,255))\n",
    "print(np.unique(img[:,:,0].flatten(), return_counts=True))\n",
    "imask = mask>0\n",
    "col = np.zeros_like(img_hsv, np.uint8)\n",
    "col[imask] = img_hsv[imask]\n",
    "col = cv2.cvtColor(col,cv2.COLOR_HSV2BGR)\n",
    "col = cv2.resize(col, (0,0), fx = 0.3, fy = 0.3, interpolation=cv2.INTER_NEAREST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow('col', col)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 조절\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_near = cv2.resize(img_gray, (0,0), fx = 2, fy = 2, interpolation=cv2.INTER_NEAREST)\n",
    "img_linear = cv2.resize(img_gray, (0,0), fx = 2, fy = 2, interpolation=cv2.INTER_LINEAR)\n",
    "img_cubic = cv2.resize(img_gray, (0,0), fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img_near', img_near)\n",
    "cv2.imshow('img_linear', img_linear)\n",
    "cv2.imshow('img_cubic', img_cubic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('./test_img/face_detect03.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "gray_face = gray[ faces[0][1]:faces[0][1]+faces[0][3],faces[0][0]:faces[0][0]+faces[0][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('./test_img/face_detect04.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "gray_face = gray[ faces[0][1]:faces[0][1]+faces[0][3],faces[0][0]:faces[0][0]+faces[0][2]]\n",
    "img_cubic = cv2.resize(gray_face, (0,0), fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('gray_face', gray_face)\n",
    "cv2.imshow('img_cubic', img_cubic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = img[ faces[0][1]:faces[0][1]+faces[0][3],faces[0][0]:faces[0][0]+faces[0][2]]\n",
    "img_cubic = cv2.resize(face, (0,0), fx = 1.5, fy = 1.5, interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('face', face)\n",
    "cv2.imshow('img_cubic', img_cubic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('./test_img/face_detect01.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "gray_face = img[ faces[0][1]:faces[0][1]+faces[0][3],faces[0][0]:faces[0][0]+faces[0][2]]\n",
    "# gray_face = gray[ faces[0][1]:faces[0][1]+faces[0][3],faces[0][0]:faces[0][0]+faces[0][2]]\n",
    "\n",
    "img_near = cv2.resize(gray_face, (0,0), fx = 1.5, fy = 1.5, interpolation = cv2.INTER_NEAREST)\n",
    "img_bi = cv2.resize(gray_face, (0,0), fx = 1.5, fy = 1.5, interpolation = cv2.INTER_LINEAR)\n",
    "img_cubic = cv2.resize(gray_face, (0,0), fx = 1.5, fy = 1.5, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('gray_face', gray_face)\n",
    "cv2.imshow('img_near', img_near)\n",
    "cv2.imshow('img_bi', img_bi)\n",
    "cv2.imshow('img_cubic', img_cubic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('teamP': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2609a2b9096678a109be2a8ba02f88f98b4c4bcbf60615abe3360d8f8e35f61b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
